\documentclass[11 pt, twoside]{article}
\usepackage{textcomp}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{indentfirst} %Comment out for no first paragraph indent
\usepackage[parfill]{parskip}
\usepackage{setspace}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{outlines}

\usepackage{fancyhdr}
\pagestyle{fancy}
\cfoot{\hyperlink{content}{\thepage}}
\lhead{}
\chead{}
\rfoot{}
\lfoot{}
\rhead{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}


\usepackage{hyperref}
\hypersetup {
	colorlinks,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black
}

\newcommand{\sepitem}{0pt} %Added room between items on the list, not including a list and its sublist
\newcommand{\seppar}{1pt} %Between items and lists overall

\setenumerate[1]{itemsep=\sepitem, parsep=\seppar}
\setenumerate[2]{itemsep=\sepitem, parsep=\seppar}
\setenumerate[3]{itemsep=\sepitem, parsep=\seppar}
\setenumerate[4]{itemsep=\sepitem, parsep=\seppar}

\newenvironment{outline*}
{
	\begin{outline}[enumerate]
	}
	{\end{outline}
}

\newcommand{\foot}[1]{\hyperlink{#1}{$_#1$}}

\begin{document}

\title{}
\author{Avery Karlin}
\date{Fall 2015}
\newcommand{\textbook}{}
\newcommand{\teacher}{}

\maketitle
\newpage
\hypertarget{content}{\tableofcontents}
\vspace{11pt}
\noindent
\underline{Primary Textbook}: \textbook\\
\underline{Teacher}: \teacher
\newpage

\section{Chapter 1 - Introduction}
\begin{outline*}
\1 Computer systems are viewed from a bottom up approach of how transistors run basic programs and a top down approach of how complicated programs are converted into simple logic commands
\2 This is used to understand commands a computer does well and does badly to program more efficiently, and to understand how changes in technology change the speed of computing
\2 C is used due to being high level enough to write large programs, but low level enough to allow direct modification of bits
\1 The concept of abstraction is central to computer science, focusing on a higher level, rather than the component ideas to save time and mental effort, assuming the details work
\2 On the other hand, it must go in turn with deconstruction, breaking down an abstract idea into more concert sub-ideas, the opposite of abstraction, in case there is a problem
\1 The concept of viewing hardware and software as joint components of a single system, which must both be taken into account to design either, is another central idea, to design the most effective components
\1 Processors/CPUs are the primary unit of a computer, used to direct the processing of information and perform the calculations required to process it, though there are other components to make use easier
\2 Originally, they were made of large boards covered in integrated circuit packages, but now are just a single silicon microprocessor chip with millions of transistors
\2 Memory is another major component, made up of a series of slots, each with an address and able to hold a single value, connected to CPU
\2 Programs are sets of instructions executed one at a time, stored in memory, while the program counter contains the current/next instruction in the program, often just incrementing after each
\1 The only limitations of computers are time and amount of memory, but otherwise all computers can do the same tasks, though not at the same pace
\2 This is due to computers being universal computing devices, as digital machines which could be increased in precision unlike analog/physical machines, but which were not made for individual tasks
\2 Turing in 1937 proposed the Turing machine, which would be able to carry out all computations of some type, and later began to define what computation is, abstracting tasks by a black box model, showing the task, input, and output, with no specification about how it is performed
\3 Turing's thesis states that a Turing machine can do all computations, such that improvements to it do not change the amount of computations, making a universal Turing machine able to simulate all different Turing machines
\2 Computers/universal Turing machines are able to do any computations, due to being programmable
\1 Computer problems must be converted into voltages to influence the flow of electrons which the computer is made of, made of a series of methods to allow carrying out of complex tasks
\2 The levels of transformation are the levels of choice to convert the problem into an electron flow for the computer, starting with the statement in a natural/human language, which has too much ambiguity to give directly to the computer
\2 The first transformation is to an algorithm, or a finite step by step procedure, with definiteness, or precisely stated, and effective compatibility, or able to be carried out by a computer,
\3 There are many possible algorithms, depending on the number of steps allowed concurrently by the computer, with many different speeds and lengths
\2 After, it is converted to a mechanical/programming language, specifically created to avoid ambiguity, often designed for specific purposes
\3 High level languages are those far from the computer itself, often machine independent, such that they don't rely on the computer specifics, such as C
\3 Low level languages are specific to the computer, such that there is one for each computer generally, called assembly
\2 The third level is conversion into the computers instruction set architecture (ISA), or the specification of interface between programs and the hardware, generally x86 on Intel processors
\3 The ISA specifies the instructions and operations the computer can do, what inputs (operands) it requires, and the operand formats (data types) it is able to accept
\3 It also contains mechanisms for the computer to find operands, called addressing modes, the number of unique memory locations, and the number of bits in each location
\3 High level languages are converted to ISA format by a compiler, while low level languages are converted by an assembler
\2 After, the ISA is transformed into an implementation, based on the microprocessor-specific microarchitecture
\3 Unlike the ISA, which specifies what the computer can do, the microarchitecture specifies how the computer actually performs those tasks
\2 The microarchitecture is made out of logic circuits, determining the trade-off of cost and efficiency during manufacturing, each of which is further made out of a specific type of circuit materials, with its own specifications
\end{outline*}
\section{Chapter 2 - Bits, Data Types, and Operations}
\begin{outline*}
\1 The movement of electrons is controlled by devices reacting to the presence of voltage, rather than the amount for simplicity
\2 These voltages are signified by binary digits/bits, 1 for voltage near the maximum, and 0 for voltage near zero (rounding due to device variation)
\2 Bits are then combined to get a large number of distinct values
\1 Data types are representations of values in which operations are encoded within the data types, mainly using 2's complement integers, ASCII codes, and floating points
\2 Unsigned integers are used to identify locations and counts, represented by positional binary representation, ranging from 0 to $2^k - 1$ for k binary digits, added normally
\2 Signed integers are used for arithmetic, with a leading 0 to signify positive, from 0 to $2^{k-1} - 1$ for k binary digits, using different systems for negative
\3 The signed magnitude system uses a leading 1 for a negative value, with a leading 1 on 0 signifying -0
\3 The 1's complement system uses a leading 1 for negative values, signifying it is equivalent to switching every other binary digit in the value (complement) to get the magnitude
\3 The 2's complement system is the standard data type, equivalent to the 1's complement - 1 for each negative value, found to be easiest to design hardware to do arithmetic on
\1 Computers generally use an arithmetic and logic unit (ALU) for addition, converting two inputs to one output of the sum, performing it in the same column method with carrying as standard addition, without actually determining the values, leading to the 2's complement system
\2 Thus, it is necessary for the sum of a number and its inverse to equal 0, ignoring all extra digits, such that only the correct number of digits is kept, and it is necessary for the sequence to be equal to one added, such that it works for results in the range, providing the advantage of the complements
\2 The advantage of 2's complement over 1's complement is making full use of the maximum amount of digits, rather than having two versions of 0
\2 The precision of the value is the number of numerical bits, while the range is the maximum magnitude of the bit sequence
\1 Since addition is the main arithmetic bit operation, subtraction of bits is simply done by adding the additive inverse of the second value
\2 Left shifts are equivalent to shifting all values to the left, adding a zero as the rightmost, dropping the overflow, equal to multiplying by 2 assuming no overflow
\2 Arithmetic right shifts are shifting to right, adding the sign bit as the leftmost, while logical right shifts are shifting to the right, adding a 0 as the leftmost, equal to dividing by 2 for arithmetic shifts, and dividing unsigned by 2 for logical
\3 For odd values shifted right, the result is rounded based on the value in the 2nd rightmost spot
\2 Sign extension/SEXT is used to shrink the amounts of bits used for a smaller number, removing all but one leading zero for positive, all but one leading one for negative
\3 Vice versa, the leading digits can be added, due to requiring the same number of bits used for adding or subtracting
\2 Overflow is noted by the loss of the leading digit, such that the sum of two positive is negative, or vice versa, such it can be dealt with
\3 For unsigned addition, an outgoing carry denotes an overflow to be dealt with
\1 Logical operations are based on viewing binary as true/1 and false/0, and are binary functions, requiring two logical inputs/bits
\2 They are also able to be used on sequences of bits of the same length, testing corresponding bits from each
\3 Bit masks are sequences which are used to separate/modify specific bits from a sequence, using logical operations
\2 Bit-wise AND returns 1 iff both inputs are 1, bit-wise OR (inclusive OR) returns 0 iff both inputs are 0, and bit-wise XOR (exclusive OR) returns 1 iff only one of the inputs is 1
\2 The NOT/complement function takes a single input (unary function), inverting/switching each of the bits in the sequence
\1 Bit vectors are binary sequences used to track if units are available/1 or busy/0, numbering units from right to left, starting with 0
\1 Floating points are used to describe numbers of a high range, but low precision, in terms of scientific notation, such that for a 32 bit float, 1 signifies the sign (1 negative, 0 positive), then 8 for the range/exponent, then 23 for the precision/fraction
\2 This is also called single, while doubles are similarly denoted, though the exponent is 11 bits, while the fraction is 52 bits
\3 Thus, doubles have an exponent from 0 to 2047 instead of 0 to 255, with a bias of 1023
\2 Thus, the number is equal to (1 + fraction) * $2^{exponent - 2^7 + 1}$, where the exponent is not allowed to be 0 or the maximum exponent
\3 If the exponent is 0, it is valued as if it is 1 under the IEEE 754 Standard for Floating Point Arithmetic
\3 As a result, the 127 added to the exponent is called the bias, allowing for negative exponents as well
\2 The fraction is found by converting the numerator and whole number to binary, then shifting to find the real exponent value, such that the fraction is the sequence except the leading 1
\3 This is done similarly to how it would be found for scientific notation, except that both parts are converted to binary before
\3 The fraction can be thought to be continuing on the binary exponents, continuing as $2^{-1}$, $2^{-2}$ and so forth
\3 Due to converting non-binary denominator fractions into floating points, it can lead to various rounding errors, such that arithmetic with it would be close, but not exactly correct
\4 Thus, bounds of error are used to check the result, rather than equality functions
\2 The sign bit is unrelated to the two's complement format
\1 ASCII (American Standard Code for Information Interchange) converts character codes from input and output into unique 8 bit codes universally
\2 As a result, keys generally have multiple associated codes, due to different characters able to be produced by each
\1 Hexadecimal notation easily is produced from binary, taking 4 bit blocks (nibbles) into binary digits for human ease, used identically to binary of that form, able to be added similarly
\2 An additional bit at the end is removed similarly to twos complement, and overflow is noted and dealt with by the same means
\end{outline*}
\section{Chapter 3 - Digital Logic Structures}
\subsection{Building Blocks}
\begin{outline*}
\1 Microprocessors are generally made of metal-oxide semiconductor (MOS) transistors, divided into p and n types, each with three terminals, the gate, source, and drain
\2 For some amount of voltage, generally 2.9 V, supplied to the gate of an n-type, the switch turns on, such that electricity can move from the source to the drain, forming a closed circuit
\3 This is generally only denoted by shorthand in drawings by the gate, which is written out, while the other terminals are just drawn as wire, denoted overall by a parallel line next to the wire with the gate coming from it
\3 p-type transistors have a small circle between the gate and the line leading to the gate
\2 p-type transistors work the opposite manner, acting as a wire only when there is virtually no voltage, while acting as an open circuit if 2.9 V is placed in the gate
\2 As a result, circuits with both types are called complementary metal-oxide semiconductor (CMOS) circuits
\1 Logic gate structures are transistor circuits for the purposes of logical functions, AND, OR, and NOT/Inverter gates as the fundamental gates, depending only on the current input
\2 These can be drawn either in pull-up network (PUN), drawing from p-type transistors connected to the original source, switching from in-series to parallel or vice versa when at the n-type
\3 In this case, AND is parallel, OR is in series, automatically adding a NOT without an inverter
\3 It can also be down pull-down network (PDN), drawn from the grounding to the n-type, such that AND is in series, OR is parallel, automatically adding a NOT without an inverter, considered easier
\2 NOT gates are made up of two MOS transistors of opposite types, current flowing into the gates, the input leading to the gates of both, with a power/voltage going into the source of the p-type
\3 The drain of the p-type is connected to the output and the source of the n-type, with the drain of the n-type grounded
\3 Thus, if there is voltage to the gates, voltage flows from the source to the output, while otherwise, voltage flows from the inputs to the ground, with none to the output, the latter necessary to create a grounded circuit if broken
\3 Inverters are drawn as a triangle with a small circle before the output wire, or can be drawn with just the small bubble/circle to show inversion as a shorthand
\2 The NOR (Not OR) gate has two p-type in series, each with a separate input, and with each input connected to one of two parallel n-type resistors, which are connected in series to the p-types, with the output between
\3 Each n-types are grounded, with voltage automatically flowing to the first p-type, such that it acts similarly to two NOT gates combined, such that the gate is grounded unless there is an output as well
\3 OR gates are then created by adding an inverter to the output of the NOR gate
\3 NOR gates are drawn as a crest-like shape, with an input to each horn, the output from the bottom point, with a small circle before the output wire, OR gates without the circle, XOR without a circle, but with an additional crest line mirroring the main one on the bottom
\2 NAND (Not AND) gates have two parallel p-type transistors, each connected to an input and a voltage source, joining to the output, each connected to one of two in series n-types connected to the ground
\3 As a result, the circuit is grounded only if the output is zero, such that there is current through both inputs, while otherwise current is through the output
\3 AND gates as a result are just NAND gates with an added inverter after
\3 NAND gates are drawn as a closed semi-circle with a small circle before the output line, with two input lines, while AND gates are drawn without the circle
\2 DeMorgan's Law states that NOT(A OR B) = (NOT A) AND (NOT B), showing the relationship between the NOT and OR gates
\3 It follows as a result that NOT(A AND B) = (NOT A) OR (NOT B) is also a valid form 
\2 Boolean algebra is also often written in the form of $\cdot$ as AND, + as OR, and $^-$ as NOT, with the order of operations as NOT, AND, then OR
\3 As a result, $X \cdot 0 = 0, X + 1 = 1, X \cdot 1 = X$, and $X + 0 = X$ as the main identities, with both associative properties of AND and OR, and distributive property of AND over OR and of OR over AND
\2 Karnaugh Maps convert a logic array to a statement, making one side of the square the possible combinations of half the variables, the other side the other half
\3 It is drawn such that any adjacent cells differ by one variable, including across borders, though not diagonally, such that the order is 00-01-11-10, instead of 00-01-10-11 which is sequential binary
\3 Adjacent entries of some power of 2 as a result can be designated as an AND, signifying the change from each, adding each separate group together with an OR, even if containing values held by other groups
\2 The binary gates can be extended as a result to a larger number of inputs by extending the number of transistors that make up the gate, thought it is noted that more levels creates a delay of that magnitude
\end{outline*}
\subsection{Combinational Circuits}
\begin{outline*}
\1 Combinational logic circuits, or decision elements, are structures of logic gates, depending only on immediate input data provided, rather than any stored data, contrasting data storage structures
\2 Decoders are a circuit which takes two inputs, and returns four bits based on which combination of the inputs is 1, called the opcode, used often for turning on a specific hardware unit
\3 It thus decodes two ordered inputs, returning 1000 if 00 is the input, 0100 if 01, 0010 if 10, and 0001 if 11
\3 This is done by placing four AND gates in parallel, each with a varying number and sequence of inverters directly before them
\2 Mux, or multiplexers, select one of two inputs to use as output based on the select signal
\3 This is done by feeding the select signal and its inversion into two AND gates, each with one input going to it, combining the results in an OR gate to return the chosen value
\3 This is extended to more inputs by increasing the number of possible select signals to the AND gate
\3 This is drawn by a trapezoid with the select signal going to a leg, the inputs to the longer side, the output from the shorter, or as a rectangle
\4 Multiple select signals can be denoted by a slash on the wire with the number of signals written above the slash
\2 Full adders take three one bit inputs, $a_i, b_i$, and the $carry_i$, such that the two results are $s_i$ and $carry_{i + 1}$, used to sum two bits in a column, adding the three inputs into 8 series of AND gates, each with a different combination of inverters before
\3 The results of the OR gates are then fed into two OR gates, depending on how they combine for the truth table, to produce the sum of the column
\3 Thus, for a 2s complement or unsigned numbers, since it can be added in columns just as a decimal number, each full adder can be used for a different column, taking the carry of the previous, to produce the sum of binary digits
\3 These are drawn as either a square with an indication mark in the middle for a single unit with the carry going in from the right, out from the left, inputs from the top, output from the bottom
\4 For a complete full adder, it is drawn as a trapezoid with the inputs to the larger end, the inward carry to the top leg, and the output from the small end
\3 Subtraction is thus done by a full added by negating one of the input bits, then adding a carry of one to the sum based on the rules of 2's complement
\3 Half adders are defined as an adder without an initial carry input, though still with a carry output
\2 The Programmable Logic Array (PLA) has an array of AND gates with a combination of inputs, such that for n inputs, there must be $2^n$ AND gates, each with varying negations
\3 These are then connected in some formation to an array of OR gates for each output, based on if the inputs produce each output
\3 This as a result is able to be used to form any truth table in circuit form, consisting of only AND, OR, and NOT gates, such that those sets of gates are called logically complete
\3 While PLAs are able to implement any circuit, they are often not the most efficient method of creating the circuit
\3 Multiple bit inputs and outputs are denoted by a slash with the number of bits written next to the slash
\2 Arithmetic Logic Unit are thus made by a full adder, often combined with a decoder to separate between signals for AND, OR, ADD, or SUB, with a Mux to use the same adder for ADD and SUB
\end{outline*}
\subsection{Memory}
\begin{outline*}
\1 Basic storage elements are logical structures capable of storing some amount of data, contrasting combinational logic circuits
\2 R-S latches can store a single bit, made of two NAND gates, the output of each connected to the input of the other, with two external inputs (S and R)
\3 In the quiescent state, S and R both begin as 1, such that whichever default input reaches first makes that output 1, at which point the other NAND gate returns 0, preserving the outputs
\3 If the S gate returns 1, then the overall data value is 1, otherwise 0, such that S or R can be set to 0 quickly to make that gate return 1, setting the variable as one of the values
\3 The term clearing the variable is used to denote setting it back to 0, such that clearing S or R makes that gate have a 1 output
\3 Both inputs are not able to be set to 0, in which case the result will depend on the electrical properties of the transistors, rather than logic
\3 As a result, the S gate signal is taken separately to get the overall output of the circuit
\2 Gated D latches allow it to be controlled when a latch is set or cleared, such that it is two NAND gates, each gaining input from D, the gate in series with the R gate inverted, such that it determines which is set
\3 Each of the D gates also have a write-enable signal, which determines if the byte is set in the first place, such that if it is activated briefly, one of the D gates stops signaling, setting the R-S latch based on D
\2 Registers store a series of bits as a unit, made up of a series of gated D latches, designated as an array of bits, starting from $[0]$ as the rightmost
\3 The same write-enable signal is given to each of the D latches, with a different D value given to each based on the value being stored
\3 Subunits of the series of bits are designated $[l:r]$ where l is the value of the leftmost, r is the value of the rightmost, called a field of the register
\1 Memory is made up of a large number of locations, each with a unique identifier, or address, each storing some amount of data, the amount of bytes/bits (1 byte = 8 bits), called the addressability of the memory
\2 The total number of addresses is called the memory's address space, as some power of two based on the numbers of bits encoded as each memory address, such that the range is $[0, 2^{n} - 1]$
\2 Most memory systems are byte addressable, such that they store a single byte per memory address, corresponding to one ASCII character, but computers are often 64-bit addressable to allow for double floating point numbers to be stored, used in large calculations
\1 Memory is denoted as size m by n bits, where m is the address space, n is the addressability, made up of a decoder to determine which memory address row, called the word line, with the size of the addressability
\2 The decoder sends the word line value into the mux, to determine which D latch provides the value through the mux, sending it to each column of D-latch/mux combinations to give one bit of the word
\2 The write enabled is connected to an AND gate with the decoder, such that the decoder signal must be set to the correct word line, along with the write enabled to set the latches
\2 Each column of mux/D-latches is also connected to a D input value to set the byte if the write enabled is activated
\end{outline*}
\subsection{Sequential Logic Circuit}
\begin{outline*}
\1 Combinational logic circuits are those that have no ability to store data from the past, while storage circuits store data from the past
\2 On the other hand, sequential logic circuits do both, such that they base the decisions on both the previous stored output and current input data, used for finite state machines 
\2 As a result, this is capable of monitoring sequences, such as a sequential rotation lock
\1 Thus, sequential circuits rely on the state of the circuit, defined as the external data of the input and current setting fed in, combined with all prior operations in the sequence and the settings deemed relevant 
\2 Each step within the sequence is thus considered a state of the system, as a snapshot of the current characteristics of the system
\2 Finite state machines are thus defined as a system with a finite number of states, external inputs, external outputs, as well as explicit specification of state transitions and what determines an external output value
\3 These are represented by a state diagram, drawing a circle for each state, with connections/arcs from the current state to each other subsequent/next state, each with the external input to provide that transition written at the base
\3 The internal output values of the system are written near the state, designating the code provided for the state, with the external output written inside the state bubble
\1 State transitions are often defined by a clock circuit, with a signal alternating between 0 and 1 cyclically in some amount of time, triggering a transition when on
\1 Thus, the combinational logic circuit aspect of the circuit is created based on the combination necessary, the storage element acting as a master-slave flip-flop instead of a gated D latch, which would modify the value stored immediately, rather than waiting until the next clock cycle
\2 Thus, the master-slave flip-flop is made up of two D-latches for each byte, the output of one as the input of the other, the clock connected as the write-enabled, but negated for one, such that it is only able to change the value of one at a time
\2 As a result, it writes the second when the clock is activated writing the value from the first, such that it is inputted into the circuit, and when the clock is deactivated, writes the first with the new value of the circuit
\end{outline*}
\end{document}
