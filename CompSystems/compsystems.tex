\documentclass[11 pt, twoside]{article}
\usepackage{textcomp}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{indentfirst} %Comment out for no first paragraph indent
\usepackage[parfill]{parskip}
\usepackage{setspace}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{outlines}

\usepackage{fancyhdr}
\pagestyle{fancy}
\cfoot{\hyperlink{content}{\thepage}}
\lhead{}
\chead{}
\rfoot{}
\lfoot{}
\rhead{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}


\usepackage{hyperref}
\hypersetup {
	colorlinks,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black
}

\newcommand{\sepitem}{0pt} %Added room between items on the list, not including a list and its sublist
\newcommand{\seppar}{1pt} %Between items and lists overall

\setenumerate[1]{itemsep=\sepitem, parsep=\seppar}
\setenumerate[2]{itemsep=\sepitem, parsep=\seppar}
\setenumerate[3]{itemsep=\sepitem, parsep=\seppar}
\setenumerate[4]{itemsep=\sepitem, parsep=\seppar}

\newenvironment{outline*}
{
	\begin{outline}[enumerate]
	}
	{\end{outline}
}

\newcommand{\foot}[1]{\hyperlink{#1}{$_#1$}}

\begin{document}

\title{Computer Systems}
\author{Avery Karlin}
\date{Fall 2015}
\newcommand{\textbook}{}
\newcommand{\teacher}{}

\maketitle
\newpage
\hypertarget{content}{\tableofcontents}
\vspace{11pt}
\noindent
\underline{Primary Textbook}: \textbook\\
\underline{Teacher}: \teacher
\newpage

\section{Chapter 1 - Introduction}
\begin{outline*}
\1 Computer systems are viewed from a bottom up approach of how transistors run basic programs and a top down approach of how complicated programs are converted into simple logic commands
\2 This is used to understand commands a computer does well and does badly to program more efficiently, and to understand how changes in technology change the speed of computing
\2 C is used due to being high level enough to write large programs, but low level enough to allow direct modification of bits
\1 The concept of abstraction is central to computer science, focusing on a higher level, rather than the component ideas to save time and mental effort, assuming the details work
\2 On the other hand, it must go in turn with deconstruction, breaking down an abstract idea into more concert sub-ideas, the opposite of abstraction, in case there is a problem
\1 The concept of viewing hardware and software as joint components of a single system, which must both be taken into account to design either, is another central idea, to design the most effective components
\1 Processors/CPUs are the primary unit of a computer, used to direct the processing of information and perform the calculations required to process it, though there are other components to make use easier
\2 Originally, they were made of large boards covered in integrated circuit packages, but now are just a single silicon microprocessor chip with millions of transistors
\2 Memory is another major component, made up of a series of slots, each with an address and able to hold a single value, connected to CPU
\2 Programs are sets of instructions executed one at a time, stored in memory, while the program counter contains the current/next instruction in the program, often just incrementing after each
\1 The only limitations of computers are time and amount of memory, but otherwise all computers can do the same tasks, though not at the same pace
\2 This is due to computers being universal computing devices, as digital machines which could be increased in precision unlike analog/physical machines, but which were not made for individual tasks
\2 Turing in 1937 proposed the Turing machine, which would be able to carry out all computations of some type, and later began to define what computation is, abstracting tasks by a black box model, showing the task, input, and output, with no specification about how it is performed
\3 Turing's thesis states that a Turing machine can do all computations, such that improvements to it do not change the amount of computations, making a universal Turing machine able to simulate all different Turing machines
\2 Computers/universal Turing machines are able to do any computations, due to being programmable
\1 Computer problems must be converted into voltages to influence the flow of electrons which the computer is made of, made of a series of methods to allow carrying out of complex tasks
\2 The levels of transformation are the levels of choice to convert the problem into an electron flow for the computer, starting with the statement in a natural/human language, which has too much ambiguity to give directly to the computer
\2 The first transformation is to an algorithm, or a finite step by step procedure, with definiteness, or precisely stated, and effective compatibility, or able to be carried out by a computer,
\3 There are many possible algorithms, depending on the number of steps allowed concurrently by the computer, with many different speeds and lengths
\2 After, it is converted to a mechanical/programming language, specifically created to avoid ambiguity, often designed for specific purposes
\3 High level languages are those far from the computer itself, often machine independent, such that they don't rely on the computer specifics, such as C
\3 Low level languages are specific to the computer, such that there is one for each computer generally, called assembly
\2 The third level is conversion into the computers instruction set architecture (ISA), or the specification of interface between programs and the hardware, generally x86 on Intel processors
\3 The ISA specifies the instructions and operations the computer can do, what inputs (operands) it requires, and the operand formats (data types) it is able to accept
\3 It also contains mechanisms for the computer to find operands, called addressing modes, the number of unique memory locations, and the number of bits in each location
\3 High level languages are converted to ISA format by a compiler, while low level languages are converted by an assembler
\2 After, the ISA is transformed into an implementation, based on the microprocessor-specific microarchitecture
\3 Unlike the ISA, which specifies what the computer can do, the microarchitecture specifies how the computer actually performs those tasks
\2 The microarchitecture is made out of logic circuits, determining the trade-off of cost and efficiency during manufacturing, each of which is further made out of a specific type of circuit materials, with its own specifications
\end{outline*}
\section{Chapter 2 - Bits, Data Types, and Operations}
\begin{outline*}
\1 The movement of electrons is controlled by devices reacting to the presence of voltage, rather than the amount for simplicity
\2 These voltages are signified by binary digits/bits, 1 for voltage near the maximum, and 0 for voltage near zero (rounding due to device variation)
\2 Bits are then combined to get a large number of distinct values
\1 Data types are representations of values in which operations are encoded within the data types, mainly using 2's complement integers, ASCII codes, and floating points
\2 Unsigned integers are used to identify locations and counts, represented by positional binary representation, ranging from 0 to $2^k - 1$ for k binary digits, added normally
\2 Signed integers are used for arithmetic, with a leading 0 to signify positive, from 0 to $2^{k-1} - 1$ for k binary digits, using different systems for negative
\3 The signed magnitude system uses a leading 1 for a negative value, with a leading 1 on 0 signifying -0
\3 The 1's complement system uses a leading 1 for negative values, signifying it is equivalent to switching every other binary digit in the value (complement) to get the magnitude
\3 The 2's complement system is the standard data type, equivalent to the 1's complement - 1 for each negative value, found to be easiest to design hardware to do arithmetic on
\1 Computers generally use an arithmetic and logic unit (ALU) for addition, converting two inputs to one output of the sum, performing it in the same column method with carrying as standard addition, without actually determining the values, leading to the 2's complement system
\2 Thus, it is necessary for the sum of a number and its inverse to equal 0, ignoring all extra digits, such that only the correct number of digits is kept, and it is necessary for the sequence to be equal to one added, such that it works for results in the range, providing the advantage of the complements
\2 The advantage of 2's complement over 1's complement is making full use of the maximum amount of digits, rather than having two versions of 0
\2 The precision of the value is the number of numerical bits, while the range is the maximum magnitude of the bit sequence
\1 Since addition is the main arithmetic bit operation, subtraction of bits is simply done by adding the additive inverse of the second value
\2 Left shifts are equivalent to shifting all values to the left, adding a zero as the rightmost, dropping the overflow, equal to multiplying by 2 assuming no overflow
\2 Arithmetic right shifts are shifting to right, adding the sign bit as the leftmost, while logical right shifts are shifting to the right, adding a 0 as the leftmost, equal to dividing by 2 for arithmetic shifts, and dividing unsigned by 2 for logical
\3 For odd values shifted right, the result is rounded based on the value in the 2nd rightmost spot
\2 Sign extension/SEXT is used to shrink the amounts of bits used for a smaller number, removing all but one leading zero for positive, all but one leading one for negative
\3 Vice versa, the leading digits can be added, due to requiring the same number of bits used for adding or subtracting
\2 Overflow is noted by the loss of the leading digit, such that the sum of two positive is negative, or vice versa, such it can be dealt with
\3 For unsigned addition, an outgoing carry denotes an overflow to be dealt with
\1 Logical operations are based on viewing binary as true/1 and false/0, and are binary functions, requiring two logical inputs/bits
\2 They are also able to be used on sequences of bits of the same length, testing corresponding bits from each
\3 Bit masks are sequences which are used to separate/modify specific bits from a sequence, using logical operations
\2 Bit-wise AND returns 1 iff both inputs are 1, bit-wise OR (inclusive OR) returns 0 iff both inputs are 0, and bit-wise XOR (exclusive OR) returns 1 iff only one of the inputs is 1
\2 The NOT/complement function takes a single input (unary function), inverting/switching each of the bits in the sequence
\1 Bit vectors are binary sequences used to track if units are available/1 or busy/0, numbering units from right to left, starting with 0
\1 Floating points are used to describe numbers of a high range, but low precision, in terms of scientific notation, such that for a 32 bit float, 1 signifies the sign (1 negative, 0 positive), then 8 for the range/exponent, then 23 for the precision/fraction
\2 This is also called single, while doubles are similarly denoted, though the exponent is 11 bits, while the fraction is 52 bits
\3 Thus, doubles have an exponent from 0 to 2047 instead of 0 to 255, with a bias of 1023
\2 Thus, the number is equal to (1 + fraction) * $2^{exponent - 2^7 + 1}$, where the exponent is not allowed to be 0 or the maximum exponent
\3 If the exponent is 0, it is valued as if it is 1 under the IEEE 754 Standard for Floating Point Arithmetic
\3 As a result, the 127 added to the exponent is called the bias, allowing for negative exponents as well
\2 The fraction is found by converting the numerator and whole number to binary, then shifting to find the real exponent value, such that the fraction is the sequence except the leading 1
\3 This is done similarly to how it would be found for scientific notation, except that both parts are converted to binary before
\3 The fraction can be thought to be continuing on the binary exponents, continuing as $2^{-1}$, $2^{-2}$ and so forth
\3 Due to converting non-binary denominator fractions into floating points, it can lead to various rounding errors, such that arithmetic with it would be close, but not exactly correct
\4 Thus, bounds of error are used to check the result, rather than equality functions
\2 The sign bit is unrelated to the two's complement format
\1 ASCII (American Standard Code for Information Interchange) converts character codes from input and output into unique 8 bit codes universally
\2 As a result, keys generally have multiple associated codes, due to different characters able to be produced by each
\1 Hexadecimal notation easily is produced from binary, taking 4 bit blocks (nibbles) into binary digits for human ease, used identically to binary of that form, able to be added similarly
\2 An additional bit at the end is removed similarly to twos complement, and overflow is noted and dealt with by the same means
\1 Hexadecimal notation is noted by an x before the number, while decimal notation is denoted by \# before the number, generally in assembly languages
\end{outline*}
\section{Chapter 3 - Digital Logic Structures}
\subsection{Building Blocks}
\begin{outline*}
\1 Microprocessors are generally made of metal-oxide semiconductor (MOS) field effect transistors (MOSFET), divided into p and n types, each with three terminals, the gate, source, and drain
\2 These are made up of a metal on top of the gate, with an oxide under, the main body made of Si semiconductor
\3 The N-region under the source and drain for a P-type, at the source and drain for an N-type, is made up of Si doped with P, while the P-region is made up of Si doped with Ga
\3 The P-region doping attracts surplus electrons easily within, while the N-regions are more difficult to do so, forced out
\3 Thus, current in an N-type gate pulls electrons from the body to the top, flowing out, while in a p-type, current causes it to be absorbed
\2 For some amount of voltage, generally 2.9 V, supplied to the gate of an n-type, the switch turns on, such that electricity can move from the source to the drain, forming a closed circuit
\3 This is generally only denoted by shorthand in drawings by the gate, which is written out, while the other terminals are just drawn as wire, denoted overall by a parallel line next to the wire with the gate coming from it
\3 p-type transistors have a small circle between the gate and the line leading to the gate
\2 p-type transistors work the opposite manner, acting as a wire only when there is virtually no voltage, while acting as an open circuit if 2.9 V is placed in the gate
\2 As a result, circuits with both types are called complementary metal-oxide semiconductor (CMOS) circuits
\3 These are complementary due to the N-type transistors on the bottom connected to the grounding in PDN format, and P-type transistors on the top, connected to power in PUN format
\2 Closed wires/switches are also called shorted wires within a transistor, such that it must be connected to a grounding to prevent shorting
\1 Logic gate structures are transistor circuits for the purposes of logical functions, AND, OR, and NOT/Inverter gates as the fundamental gates, depending only on the current input
\2 These can be drawn either in pull-up network (PUN), drawing from p-type transistors connected to the original source, switching from in-series to parallel or vice versa when at the n-type
\3 In this case, AND is parallel, OR is in series, automatically adding a NOT without an inverter
\3 It can also be down pull-down network (PDN), drawn from the grounding to the n-type, such that AND is in series, OR is parallel, automatically adding a NOT without an inverter, considered easier
\2 NOT gates are made up of two MOS transistors of opposite types, current flowing into the gates, the input leading to the gates of both, with a power/voltage going into the source of the p-type
\3 The drain of the p-type is connected to the output and the source of the n-type, with the drain of the n-type grounded
\3 Thus, if there is voltage to the gates, voltage flows from the source to the output, while otherwise, voltage flows from the inputs to the ground, with none to the output, the latter necessary to create a grounded circuit if broken
\3 Inverters are drawn as a triangle with a small circle before the output wire, or can be drawn with just the small bubble/circle to show inversion as a shorthand
\2 The NOR (Not OR) gate has two p-type in series, each with a separate input, and with each input connected to one of two parallel n-type resistors, which are connected in series to the p-types, with the output between
\3 Each n-types are grounded, with voltage automatically flowing to the first p-type, such that it acts similarly to two NOT gates combined, such that the gate is grounded unless there is an output as well
\3 OR gates are then created by adding an inverter to the output of the NOR gate
\3 NOR gates are drawn as a crest-like shape, with an input to each horn, the output from the bottom point, with a small circle before the output wire, OR gates without the circle, XOR without a circle, but with an additional crest line mirroring the main one on the bottom
\2 NAND (Not AND) gates have two parallel p-type transistors, each connected to an input and a voltage source, joining to the output, each connected to one of two in series n-types connected to the ground
\3 As a result, the circuit is grounded only if the output is zero, such that there is current through both inputs, while otherwise current is through the output
\3 AND gates as a result are just NAND gates with an added inverter after
\3 NAND gates are drawn as a closed semi-circle with a small circle before the output line, with two input lines, while AND gates are drawn without the circle
\2 DeMorgan's Law states that NOT(A OR B) = (NOT A) AND (NOT B), showing the relationship between the NOT and OR gates
\3 It follows as a result that NOT(A AND B) = (NOT A) OR (NOT B) is also a valid form 
\2 Boolean algebra is also often written in the form of $\cdot$ as AND, + as OR, and $^-$ as NOT, with the order of operations as NOT, AND, then OR
\3 As a result, $X \cdot 0 = 0, X + 1 = 1, X \cdot 1 = X$, and $X + 0 = X$ as the main identities, with both associative properties of AND and OR, and distributive property of AND over OR and of OR over AND
\2 Karnaugh Maps convert a logic array to a statement, making one side of the square the possible combinations of half the variables, the other side the other half
\3 It is drawn such that any adjacent cells differ by one variable, including across borders, though not diagonally, such that the order is 00-01-11-10, instead of 00-01-10-11 which is sequential binary
\3 Adjacent entries of some power of 2 as a result can be designated as an AND, signifying the change from each, adding each separate group together with an OR, even if containing values held by other groups
\2 The binary gates can be extended as a result to a larger number of inputs by extending the number of transistors that make up the gate, thought it is noted that more levels creates a delay of that magnitude
\end{outline*}
\subsection{Combinational Circuits}
\begin{outline*}
\1 Combinational logic circuits, or decision elements, are structures of logic gates, depending only on immediate input data provided, rather than any stored data, contrasting data storage structures
\2 Decoders are a circuit which takes two inputs, and returns four bits based on which combination of the inputs is 1, called the opcode, used often for turning on a specific hardware unit
\3 It thus decodes two ordered inputs, returning 1000 if 00 is the input, 0100 if 01, 0010 if 10, and 0001 if 11
\3 This is done by placing four AND gates in parallel, each with a varying number and sequence of inverters directly before them
\2 Mux, or multiplexers, select one of two inputs to use as output based on the select signal
\3 This is done by feeding the select signal and its inversion into two AND gates, each with one input going to it, combining the results in an OR gate to return the chosen value
\3 This is extended to more inputs by increasing the number of possible select signals to the AND gate
\3 This is drawn by a trapezoid with the select signal going to a leg, the inputs to the longer side, the output from the shorter, or as a rectangle
\4 Multiple select signals can be denoted by a slash on the wire with the number of signals written above the slash
\2 Full adders take three one bit inputs, $a_i, b_i$, and the $carry_i$, such that the two results are $s_i$ and $carry_{i + 1}$, used to sum two bits in a column, adding the three inputs into 8 series of AND gates, each with a different combination of inverters before
\3 The results of the OR gates are then fed into two OR gates, depending on how they combine for the truth table, to produce the sum of the column
\3 Thus, for a 2s complement or unsigned numbers, since it can be added in columns just as a decimal number, each full adder can be used for a different column, taking the carry of the previous, to produce the sum of binary digits
\3 These are drawn as either a square with an indication mark in the middle for a single unit with the carry going in from the right, out from the left, inputs from the top, output from the bottom
\4 For a complete full adder, it is drawn as a trapezoid with the inputs to the larger end, the inward carry to the top leg, and the output from the small end
\3 Subtraction is thus done by a full added by negating one of the input bits, then adding a carry of one to the sum based on the rules of 2's complement
\3 Half adders are defined as an adder without an initial carry input, though still with a carry output
\2 The Programmable Logic Array (PLA) has an array of AND gates with a combination of inputs, such that for n inputs, there must be $2^n$ AND gates, each with varying negations
\3 These are then connected in some formation to an array of OR gates for each output, based on if the inputs produce each output
\3 This as a result is able to be used to form any truth table in circuit form, consisting of only AND, OR, and NOT gates, such that those sets of gates are called logically complete
\3 While PLAs are able to implement any circuit, they are often not the most efficient method of creating the circuit
\3 Multiple bit inputs and outputs are denoted by a slash with the number of bits written next to the slash
\2 Arithmetic Logic Unit are thus made by a full adder, often combined with a decoder to separate between signals for AND, OR, ADD, or SUB, with a Mux to use the same adder for ADD and SUB
\end{outline*}
\subsection{Memory}
\begin{outline*}
\1 Basic storage elements are logical structures capable of storing some amount of data, contrasting combinational logic circuits
\2 R-S latches can store a single bit, made of two NAND gates, the output of each connected to the input of the other, with two external inputs (S and R)
\3 In the quiescent state, S and R both begin as 1, such that whichever default input reaches first makes that output 1, at which point the other NAND gate returns 0, preserving the outputs
\3 If the S gate returns 1, then the overall data value is 1, otherwise 0, such that S or R can be set to 0 quickly to make that gate return 1, setting the variable as one of the values
\3 The term clearing the variable is used to denote setting it back to 0, such that clearing S or R makes that gate have a 1 output
\3 Both inputs are not able to be set to 0, in which case the result will depend on the electrical properties of the transistors, rather than logic
\3 As a result, the S gate signal is taken separately to get the overall output of the circuit
\3 Thus, it can either be drawn with both NAND gates with crossing outputs in the same direction, or with a cycle of NAND gates, taking the output of the S gate either way
\2 Gated D latches allow it to be controlled when a latch is set or cleared, such that it is two NAND gates, each gaining input from D, the gate in series with the R gate inverted, such that it determines which is set
\3 Each of the D gates also have a write-enable signal, which determines if the byte is set in the first place, such that if it is activated briefly, one of the D gates stops signaling, setting the R-S latch based on D
\2 Registers store a series of bits as a unit, made up of a series of gated D latches, designated as an array of bits, starting from $[0]$ as the rightmost
\3 The same write-enable signal is given to each of the D latches, with a different D value given to each based on the value being stored
\3 Subunits of the series of bits are designated $[l:r]$ where l is the value of the leftmost, r is the value of the rightmost, called a field of the register
\1 Memory is made up of a large number of locations, each with a unique identifier, or address, each storing some amount of data, the amount of bytes/bits (1 byte = 8 bits), called the addressability of the memory
\2 The total number of addresses is called the memory's address space, as some power of two based on the numbers of bits encoded as each memory address, such that the range is $[0, 2^{n} - 1]$
\2 Most memory systems are byte addressable, such that they store a single byte per memory address, corresponding to one ASCII character, but computers are often 64-bit addressable to allow for double floating point numbers to be stored, used in large calculations
\1 Memory is denoted as size m by n bits, where m is the address space, n is the addressability, made up of a decoder to determine which memory address row, called the word line, with the size of the addressability
\2 The decoder sends the word line value into the mux, to determine which D latch provides the value through the mux, sending it to each column of D-latch/mux combinations to give one bit of the word
\2 The write enabled is connected to an AND gate with the decoder, such that the decoder signal must be set to the correct word line, along with the write enabled to set the latches
\2 Each column of mux/D-latches is also connected to a D input value to set the byte if the write enabled is activated
\end{outline*}
\subsection{Sequential Logic Circuit}
\begin{outline*}
\1 Combinational logic circuits are those that have no ability to store data from the past, while storage circuits store data from the past
\2 On the other hand, sequential logic circuits do both, such that they base the decisions on both the previous stored output and current input data, used for finite state machines 
\2 As a result, this is capable of monitoring sequences, such as a sequential rotation lock
\1 Thus, sequential circuits rely on the state of the circuit, defined as the external data of the input and current setting fed in, combined with all prior operations in the sequence and the settings deemed relevant 
\2 Each step within the sequence is thus considered a state of the system, as a snapshot of the current characteristics of the system
\2 Finite state machines are thus defined as a system with a finite number of states, external inputs, external outputs, as well as explicit specification of state transitions and what determines an external output value
\3 These are represented by a state diagram, drawing a circle for each state, with connections/arcs from the current state to each other subsequent/next state, each with the external input to provide that transition written at the base
\3 The internal output values of the system are written near the state, designating the code provided for the state, with the external output written inside the state bubble
\1 State transitions are often defined by a clock circuit, with a signal alternating between 0 and 1 cyclically in some amount of time, triggering a transition when on
\2 Clocks are denoted as an input by a small triangle pointing into a circuit at the entry point, drawn with one edge as an edge of the circuit
\2 The clock must have a long enough time that all charge transitions complete, creating the danger of overclocking
\1 Thus, the combinational logic circuit aspect of the circuit is created based on the combination necessary, the storage element acting as a master-slave flip-flop instead of a gated D latch, which would modify the value stored immediately, rather than waiting until the next clock cycle
\2 Thus, the master-slave flip-flop is made up of two D-latches for each byte, the output of one as the input of the other, the clock connected as the write-enabled, but negated for one, such that it is only able to change the value of one at a time
\2 As a result, it writes the second when the clock is activated writing the value from the first, such that it is inputted into the circuit, and when the clock is deactivated, writes the first with the new value of the circuit
\3 The process of changing the feed-out value when the clock activates is called positive/rising edge triggered, while the process of changing the stored when it deactivates is called negative/falling edge triggered
\3 The term clocked is used to refer to rising edge triggered generally, such that the register is written rising edge triggered, sent out falling edge triggered
\4 The PC is considered rising edge triggered as a result
\3 The temporary register identifier bits are called register specifiers
\2 Registers are generally used to refer to a set of flip-flops, rather than a set of latches, though may be used for either
\1 Static RAM is thus made up of registers, maintaining value as long as power is applied, while Dynamic RAM uses a capacitor to hold the value instead, requiring refreshing due to leaking charge
\end{outline*}
\section{Chapter 4 - Von Neumann Model}
\subsection{Hardware}
\begin{outline*}
\1 Computers are made up of a program, or a set of instructions, each a well-defined work command of the smallest possible division, and a hardware device, such that a von Neumann model is simplest fundamental model for processing programs
\2 It is made up of a memory, processing unit, input, output, and control unit (controlling the order of instructions processed), storing the program in the memory
\2 In von Neumann/computer model diagrams, filled arrows are used to signify command/control signals, while unfilled arrows are used to signify data
\1 The memory for a standard computer in modern day is $2^{28}$ by 8 bits, while the LC-3 has $2^{16}$ by 16 bits
\2 The contents from memory are read by placing the location in the memory's address register (MAR), which then has the data stored there placed in the memory's data register (MDR), written by activating Write Enable signal, then writing the address and data value in each respectively
\2 As a result, the MAR for an LC-3 has 16 bits, due to the address requiring that many to specify, while the MDR has 16 bits for one data piece as well
\1 The processing unit is made up of at least one ALU, used for simple arithmetic and logic functions, with the length of the quantity evaluated called the word length, each value a word
\2 In the LC-3, the word length is 16 bits, though most computers in modern day have either 32 bits or 64 bits (such as the SPARC-V9)
\3 Since the addressibility of the LC-3 is equal to a word, it can be called word-addressable
\2 The ALU for an LC-3 is able to perform addition, bitwise NOT, and bitwise AND
\2 Most processors also have a small amount of memory, called the TEMP, next to the ALU, to store data for calculations with multiple parts needed in the near future
\3 This is due to taking a long amount of time to access the main computer memory, relative to the time needed to  do the calculation, generally with the TEMP having a certain amount of registers, each for one word
\3 The TEMP is also called the register file, composed in the LC-4 of three MUX, a write enabled, an input, and creating two 16 bit outputs
\3 In the LC-3, it has 8 registers (R0, R1, \dots, R7), while the SPARC-V9 has 32 registers
\1 Input and output are made up of peripherals able to sense and display information, generally at the simplest the monitor and keyboard for an LC-3
\2 A simple keyboard for an LC-3 requires two registers, a KBDR for the ASCII code of the last key hit and KBSR for maintaining the status of keys hit, while a simple monitor requires two registers,  DDR for ASCII code being displayed and DSR for status information
\1 The control unit keeps track of the order of instructions in the program, using the information register (IR)/program memory to contain the current instruction being executed
\2 It also contains the address of the next instruction, stored within the program counter (PC), and a finite state machine to direct all activity taking input from the IR and from a clock (CLK)
\3 The clock is made up of a piezoelectric crystal oscillator to produce oscillating voltage, connected to an AND gate with a RUN latch as the other, determining if the computer runs
\3 Older computers used the HALT instruction to turn off the RUN latch, while newer computers, such as the LC-3 use the operating system to do so to avoid wasting an opcode
\2 The finite state machine has a series of command outputs, such as, within the LC-3, the two bit ALUK, controlling the operation of the ALU, or the GateALU, determining if the ALU output is sent out of the computer by the processor bus during that cycle
\3 The LD.MAR is the write-enabled signal for the MAR register, allowing the PC to be written into the MAR to get the subsequent command
\3 The GatePC determines if the PC is connected to the processor bus, such that the data from it can be accessed at a particular point
\3 The PCMUX allows it to choose the select line for modifying the PC in a specific manner, such as incrementing, giving the new value
\3 The LD.PC is the write-enabled signal for the PC register, while the LD.IR is the write-enabled signal for the IR, allowing the values to be modified
\3 The GateMDR determines if the MDR is connected to the processor bus, such that the value from it can be sent to other parts of the system
\3 The MARMUX determines where the address supplied to the MAR is from, either from a register or the PC, specified by the ADDR1MUX, which then determines what length immediate/zero to add to it by the ADDR2MUX
\4 The decision of which is controlled by a zero extended (positive sign) trap vector sent by the computer to determine which method is done
\4 The important of using the correct immediate length is noted by the risk of removing sections as overflow should it not be chosen correctly
\3 It is noted that while these are used for LC-3, they are specific to a particular ISA, such that they are not universally created components
\end{outline*}
\subsection{Instruction Processing}
\begin{outline*}
\1 Instructions are made up of an opcode (command) on the left, written as 4 bits $[15:12]$, in a 16 bit word, with the remaining 12 bits as the operands (data executing on)
\2 Functions such as ADD or NOT are called an operate instruction, acting to process the data
\2 Functions such as LDR are called a data movement instruction, due to moving data from one location to another
\1 The commands are processed in the six phase instruction cycle, taking up a some number of machine/clock cycles, controlled by the finite state machine
\2 It begins with the FETCH phase, taking the next instruction from memory by the address in the PC, loading it into the IR, after which the PC is incremented to point toward the next instruction, taking multiple cycles to access memory, the remaining steps each taking one
\2 After, the DECODE phase studies the opcode to direct the command, sending an output line from the DECODE box to the processor in one clock cycle made up of all control signals (distinct from control commands), then the EVALUATE ADDRESS phase, which calculates any memory addresses needed
\2 After, the FETCH OPERANDS phase takes the operands from either the memory from the EVALUATE ADDRESS phase, or from temporary storage, and then are used in the EXECUTE phase, finally using the STORE RESULT phase to finish the cycle
\2 It is noted that while there are six phases, most commands such as the ADD (EVALUATE ADDRESS) and LDR (EXECUTE) do not require specific phases each
\1 Control instructions are those which change the sequence of instructions, changing the PC after it is incremented, during the EXECUTE phase
\end{outline*}
\section{Chapter 5 - LC-3 and LC-4}
\begin{outline*}
\1 The LC-4 is a variation on the LC-3, using different formatting and cycle implementation in certain circumstances, but with generally similar conceptuals
\1 The ISA specifies all functions of the computer that can be written for the computer in machine language, meaning Instructions Set Architecture for conversion from logic or high-level languages
\2 The ISA is defined by the set of opcodes, data types of the operands, and addressing modes for a particular machine
\1 The opcodes present in a particular ISA depend on the purpose of the computer, with varying amounts based on the level of complexity
\2 Conversely, most computers prefer fewer large commands, rather allowing more variation in the instructions sent to maximize efficiency
\2 The LC-3 has 19 different opcodes, with 1101 unspecified, each for a particular command, while the LC-4 uses 36 different opcodes, each with only 4 bits for it, such that it has certain opcodes with the first four bits overlapping, using additional bits to differentiate
\1 Data types are representations of information that opcodes are able to operate on, supporting a specific format of data, such that LC-3 only supports 2's complement integers
\1 Addressing modes specify where the operand is located, found either in the instruction mode (literal/immediate operand), register mode, or within memory
\2 Addressing modes for within memory are either PC-relative, indirect, or base + offset modes, used only for data movement operands generally, using the other two for all operand types
\2 Immediate operands are limited by the length of bits allowed within the command
\1 Condition codes are single-bit registers found in the LC-3 and LC-4, set for any TEMP register writing function in LC-3, for any CMP function or any TEMP register writing in LC-4
\2 The three registers are N (negative), Z (zero), P (positive), setting automatically to allow instruction sequencing as a result of the returned value
\1 General purpose registers (GPR) are the registers/memory locations used for TEMP storage within the processor, each generally word-addressable, for the register addressing mode
\2 It is noted that the same register can be used for both the source and destination
\2 Loading is the process of moving memory to a register from the memory, while the process of moving away is storing
\2 The LC-3 has seven data movement instructions, LD, LDR, LDI, LEA, ST, STR, and STI, while the LC-4 only has LDR and STR commands, with the first three bits after the opcode being the temporary register being used for loading/storing (destination register/DR)
\3 The temporary register identifier bits are called register specifiers
\3 The remaining bits $[8:0]$ are the address generation bits, encoding the instructions for the data movement location/addressing mode
\3 LDR and STR are the base + offset mode commands, with the leftmost three as the register for the base location (source register/SR), the remaining six bits as the literal offset value
\3 LD and ST are PC-relative mode commands, providing all 9 bits as displacement from the current PC, after it has been incremented already
\3 LDI and STI are indirect address mode, providing all 9 bits as the displacement from the current PC, to a location which contains the address of the data in memory
\3 LEA is immediate mode, only able to load into a register, adding the incremented PC counter to the immediate value, which is then loaded into the register, not needing memory access
\2 The original valuing within an algorithm of variables is called the initialization
\1 Control instructions are used to change the sequence of instructions, allowing conditional branches, unconditional jumps, subroutine/function calls, TRAP, and return from interrupt
\2 The BR command is used for conditionals, checking some combination of NZP registers, if found, adding the incremented PC by the immediate offset given by the remaining bits for the new PC 
\3 The use of all three registers is called an unconditional branch
\3 Loops can either be run by iteratively, decreasing some counter each time the body of the loop executes, by iteration, or by sentinel, testing for an occurrence of some sentinel variable to stop the loop
\4 Sentinels are often unexpected character to search for, signifying the end of the sequence of expected characters
\2 The JMP command allows movement to an address as an unconditional BR, with increased immediate length, such that there is a wider range
\3 The JMPR command allows changing the PC to any address contained within a register, to allow not using the offset within a wider range
\2 The TRAP command sets R7 to the incremented PC, moving the PC to a memory address in the operating system, called an OS service call, the rightmost 8 bits as the trapvector
\3 The trapvector is an unsigned immediate that identifies the service call that the operating system is supposed to use
\3 If the trapvector is 0, 0x8000 is used in the LC-4, while in the LC-3, an input character from the keyboard is x23, output to the monitor is x21, outputting a string starting at the address in R0 (PUTS) is x22, and ending a program is x25
\4 The vector location signifies a request to move to an alternate program within the OS
\3 The output and input character must be stored in R0 for the LC-3, which is the register character automatically stored and displayed
\1 Coding in LC-3/LC-4 are done by using the mnemonic forms with spaces between the separate register codes, rather than the binary encoding or the semantic explanation
\1 The global bus of the data path allows any structure within the computer to transmit 16 bits of information to any other structure, modifying the connections within the bus to determine the source and output, transferring one at a time, though some computers have multiple buses
\2 Each component of the LC-3 has a tri-state device, drawn as a triangle, to allow the computers control to allow one device to send data through the bus at once, designated as the Gate control
\2 On the receiving side, the LD (load enabled) control determines where the signal is being received
\2 As a result, tracking the data path is the flow of data in the CPU through a single instruction cycle
\end{outline*}
\section{Chapter 7 - Assembly Language}
\subsection{Assembly Programming}
\begin{outline*}
\1 For programming-ease, machine language given by the ISA can also be denoted by assembly language, contained within each ISA, each command representing one ISA command
\2 This is then often translated into a high-level programming language such as C, moving it closer toward human language, which are ISA-independent
\3 High-level languages provide less control over the individual commands, sacrificing it for readability
\2 Each assembly command has a mnemonic name for opcodes, and allows addresses to be set equivalent to text symbolic addresses
\1 The assembler program translates assembly language, also called assembling it, into machine code for the computer
\1 Instruction lines begin with a label, then the symbolic opcode, symbolic or explicit (such as register codes) operands, and finally comments (written after a semi-colon)
\2 The label acts as a symbolic address for the memory address at that label, either storing an instruction or data
\3 In LC-3 or LC-4, labels can be placed on assembler commands .FILL and .BLKW, setting that label as the current location within the assembler to define variable names
\3 Labels are often used to designate the start of loops or functions, as well as the end of the program overall in LC-4
\2 Immediate values are written non-symbolically, such that binary is prefaced by a b, hex by an x or 0x, and decimal by an \#
\2 Comments are purely to make the code more readable to other programmers, ignoring all after the semicolon by the assembler
\3 Additional spaces and tabs are also used similarly, making the program more generally readable, though new lines can only be used at the end of a line properly
\3 Comments are generally used at the start of the program to describe inputs, outputs, limitations, and the purpose of the program
\1 Pseudo-ops/assembler directives are instructions directly to the assembler, not representing ISA opcodes, but rather to clarify the code for the assembler, denoted by a dot at the start
\2 In LC-3, the .END command functions to tell the assembler when to stop reading, while the .ORIG replaces the .ADDR command
\2 .FILL in LC-3 increments the current location within memory, then fills it with the value given, before incrementing again, while it fills the current value then increments in LC-4
\2 On the other hand, pseudo-instructions are instructions that are used as shorthand for other instructions, converted into proper assembly instructions within the code
\1 It is often wise to store the register values in some location, such that preexisting values are preserved
\2 This is essential if the value of the register is modified within the program, while the original value is needed later
\end{outline*}
\subsection{Assembly and Execution}
\begin{outline*}
\1 The assembly process converts the assembly language into machine language by the assembler software, using the ``assemble \textit{filename}.asm \textit{outfile}'' command in LC-3 assembler
\2 In LC-4, ``as \textit{filename output}'' is used instead in the assembler, producing an object (.obj) file
\2 The assembly and setup process in the LC-4 can be shortened by a script file, called by ``script \textit{filename}.txt'', containing commands
\3 The reset command is used to reset all LC-4 registers to 0, while ``set \textit{register/PC value} is used to set the values of the PC and register before the program is run
\3 The object file is loaded into the LC-4 by ``ld \textit{filename}''
\3 Breakpoints in the program are set by ``break set \textit{label/address}''
\1 The assembler requires a two-pass process due to the labels not necessarily being created before they are used
\2 The first pass creates a symbol table, identifying the binary addresses corresponding to each label, while the second pass translates to machine code
\2 During each pass, the current address code being created is kept track of by a location counter, incremented after
\3 As a result, the incremented PC for each command is the LC + 1
\1 As a computer program is executed, it is done in executable image, made up of several object files linked together
\2 Object files are either user-written and assembled, compiled from a higher level language, or built in libraries
\2 Each object file is made up of ISA binary commands as a result
\2 After it is linked into an executable file, the instruction cycle is used to run the file
\1 In LC-3, multi-object files use ``.EXTERNAL \textit{variable}'' in the assembly programs without the label, such that it would create a symbol entry for it, with a symbol notation for external
\2 When the linker program is linking the modules, it identifies the values of each external variable
\2 Programs working with each other can simply be loaded separately in, assuming no overlap in labels
\end{outline*}
\section{Chapter 8 - I/O}
\begin{outline*}
\1 I/O devices usually have at least two registers, one to display the current status, one for data
\1 Older devices had special input/output instructions built-in to the ISO, while modern devices simply use standard memory instructions to special registers, called memory-mapped I/O
\2 As a result, the MAR is loaded with the device register address, using logic to choose the device register rather than regular memory
\1 Asynchronous I/O allows the devices to operate at a rate separate from that of the processor, due to the processor clock moving vastly faster than humans can input
\2 Processing asynchronously requires a handshake protocol to coordinate, commonly using a flag 1-bit register, to indicate if the input/output has been processed up-to-date
\3 Thus, this Ready bit is set to 1 when data is inputted, 0 when processed for input, and 1 when received, 0 when displayed by output
\3 The keyboard/monitor is then disabled until the data is processed properly, such that no data is missed
\2 Synchronous I/O is a theoretical such that data is inputted at the same rate as the clock moves, such that a handshake is not needed
\2 Interrupt-driven I/O is such that the keyboard notifies the processor when a key has been used, while polling I/O is such that the processor continuously checks the ready bit
\3 The program previously running does not have to be related to the I/O device, halted to allow the I/O to be dealt with, after which it is returned to as if there was no interruption
\3 This is used to save processor power from having to constantly poll all I/O devices to receive characters
\3 Thus, it requires an enabling mechanism to generate the interrupt signal and a mechanism to handle the signal
\4 For the signal to interrupt the processor, it must be more urgent than the task currently performed by the processor
\4 The ready bit determines if the signal would be sent, with the 14th bit of the status register as the interrupt enable, able to be written or cleared by the processor depending on if desired
\4 The interrupt request is the AND gate of the ready and interrupt enable bit
\3 All processors have a level of urgency, PL7 at highest to PL0, such that a higher PL program causes the execution before other programs
\4 This is done by testing for the interrupt signal (INT) before FETCH phase, after STORE RESULT
\4 The priority encoder then determines which of the device interrupt signals is most important, and compares it to the current program
\4 After, the control unit saves the information needed to restart the program, and loads the PC with the new value, before FETCH
\1 The keyboard in LC-3/LC-4 is made up of the keyboard data register (KBDR) and the keyboard status register (KBSR), contained within xFE02 and xFE00 respectively
\2 Bits [7:0] within the KBDR are used to store the ASCII key value, the remainder containing 0
\2 Bit [15] of the KBSR contains the ready bit, while the remainder contain 0
\2 The display is similarly made up of the display data register (DDR) at xFE06 and the display status register (DSR) at xFE04, using similar storage distribution to the keyboard for console display
\3 In LC-4, it is called the ASCII display status/data register (ADDR/ADSR), stored in the same locations
\2 For polling, they are not required to be writable by the CPU, though they are required to be for interrupted I/O
\2 The timer measures the time in milliseconds, written from the initial set time in the Timer Interval Register (TIR) at xFE0A similarly
\3 The 15th bit of the Timer Status Register (TSR) at xFE08 is 1 when the timer expires, reset after the ready bit is read by the computer once it expires
\3 This is used to prevent a program from running indefinitely timing out after some preset length of time
\2 Video memory is stored in a 128 word horizontal length by 124 word vertical length array, starting in the top left from xC000, going up by one horizontally
\3 The memory stores the blue value in [4:0], green value in [9:5], and the red value in [14:10]
\1 The memory-mapped I/O is controlled in LC-3 by the ADDR.CTL logic block, linking the MAR to the memory, such that the MIO.EN signal determines if movement from I/O memory is used
\2 The R.W signal determines if data is being loaded or stored, coordinating the MAR, MDR, memory, and I/O
\2 If the load signal is indicated, it controls the INMUX to pass the correct data from memory/IO to the MDR
\end{outline*}
\section{Chapter 9 - TRAP Routines and Subroutines}
\begin{outline*}
\1 Due to hardware I/O registers being accessed by a large number of programs, giving the programmer complete control could pose problems to other programs
\2 Thus, hardware registers are considered privileged, requiring sufficient privilege to access it
\2 As a result, I/O is generally only accessible by the TRAP instruction working through the OS, which has privilege to access them
\3 Within the LC-4, this is done by moving into supervisor mode, which is able to execute both user and non-user data
\3 This is designated in the LC-4 by the Processor Status Register bit 15, containing 0 for user mode, 1 for the supervisor mode
\4 The NZP sequence is similarly stored in there, with NZP as bits [2:0] respectively
\2 Thus, the TRAP instruction is said to create a service/system call, taking control of the computer from the program until after the call
\1 The TRAP mechanism is made up of a set of service routines, built-in to the OS, a table of starting addresses for each instruction, the TRAP instruction itself, and a linkage to return control to the original program
\2 Thus the TRAP instruction moves the PC to the routine, but creates the linkage to return to the program after (storing the incremented PC in R7), jumping at the end
\2 Within the LC-4, it returns by the RTI instruction at the end of the TRAP instruction sequence, turning off supervisor mode
\2 TRAP codes are written themselves with the assembler directive ``.OS'' at the start before ``.CODE'', written above both the table portion and the instruction portion of the file
\1 TRAP is able to shut off the clock by the RUN latch, stored within bit 15 of the Machine Control Register, located in xFFFE
\1 TRAP routines and subroutines, due to using registers within the routine, need to save the initial values of those registers beforehand, or during the routine, restoring when needed
\2 Caller-save is used to describe if the calling/original program saves the registers, while callee-save describes if the routine saves the registers
\2 Within the LC-4, TRAP commands are a combination, using caller-save for the general PC-restoring R7 register, callee save for any used by the individual routines
\1 Subroutines are called similarly to OS TRAP routines, but rather written by user programmers, often contained within libraries
\2 These are also called procedures or functions, used by a call/return mechanism, distinct due to the lack of OS privilege without risk of damaging other programs
\2 The call mechanism calculates the starting address of the subroutine, loads it, and saves the return address for the return mechanism to load into the PC
\2 This is done by JSR and JSRR, the latter moving to an address in a register, the former moving to the label by the offset
\3 JSR must have the label must be .FALIGNed, due to adding the bits after the first 4 as 0s, to extend the range
\3 JSR is either the offset from x0000 or from x8000, depending on the original location
\3 Both save the incremented PC within R7 for the return mechanism
\2 Libraries are used to save time and prevent the programmer from having to know the details of every process required
\3 As a result, only a pseudo-op .EXTERNAL combined with documentation are needed by the programmer to use the library
\end{outline*}
\section{Supplemental LC-4 Notes}
\begin{outline*}
\1 The storage is made up of x0000-x1FFF for user code, x2000-x3FFF for user global variables, x4000-x6FFF for user dynamic storage/heap, and x7000-x7FFF for user local storage/stack
\2 The trap vector table is then from x8000-x80FF, the OS from x8200-xBFFF, video output/memory from xC000-xFDFF, and xFE00-xFFFF for I/O device registers
\2 Only the user portion can be accessed and modified, the code portion only able to be when loading a program, the memory portion from within the program
\1 ``reset'' puts the computer back to the initial state, ``as \textit{filename filename}'' assembles it, and ``ld \textit{filename}'' loads it in
\2 ``set \textit{register value}'' is able to set an initial memory location, PSR, or temp registers
\2 These system commands can be written within a script text file, run by ``script \textit{filename}.txt''
\3 Unlike within LC-4 code where hexadecimal is default, within scripts, decimal is the default and binary is not permitted
\1 In the documentation, PC + 1 means that the incremented PC is used, rather than that it is incremented a second time
\1 .FILL automatically increments the address after being done
\2 .BLKW moves the assembler address to after the block, setting all values to 0 within, and prevents the assembler from editing the value, returning an error if it tries, though the program is able to
\2 .CODE and .DATA directives signify which portions of the memory are able to be written by the code at any point
\2 .FALIGN moves the address to the next multiple of 16 within the assembler
\2 .STRINGZ adds a x0000 character at the end of the string to designate the end
\2 .CONST/.UCONST are replaced by the assembler to the correct value during assembly, such that it is shorthand, not a variable
\1 CONST inserts a signed value (-FF-1, FF) into some memory location, removing prior data in that location
\2 HICONST then adds an unsigned value (0, FF) into bits [15:8] of the memory location, preserving the remainder
\2 Thus, when combined with CONST, can be used to fully set the memory location, removing the sign bit from CONST, such that it must be done after
\1 Upper/lowercase letters for instructions or registers are irrelevant, such that they are corrected to capital by the compiler, except the nzp after BR, corrected to lowercase
\2 BR is used as shorthand within code for BRnzp
\2 Tabs are ignored by the assembler, but newlines imply the next instruction begins, assuming it is not a blank line
\3 Newlines are able to be used for an extra line spacing between instructions, and are able to separate the label from the instruction
\end{outline*}
\section{Chapter 6 - Programming}
\begin{outline*}
\1 Programming is divided into problem solving, converting the natural language problem into code that the computer can convert into electrons, and debugging, removing errors/bugs in the program
\2 Thus, the first step is to convert the problem into an algorithm with finiteness, definiteness (precisely stated), and effective computibility (able to be done by a computer)
\1 This is commonly done by structured programming/systematic decomposition, breaking the overall task into smaller steps, until it can be done by the computer
\2 The three constructs are sequential (each task performed until completion without option), conditional (multiple tasks, possibly vacuous (doing nothing), based on a condition), or iterative (repeating a subtask until some test returns a value)
\2 The constructs are also made such that all three to have one entrance and exit into it definitively, each assumed to be able to be done by the ISA/programming langauge
\2 The process of breaking down the task is called stepwise refinement, breaking down each complicated task step by step
\3 The task is initially broken up into three sections, initialization, calculation, and output
\3 Each is then divided into one or more constructs, until it is purely within manageable tasks for the programming language
\2 The stepwise refinement is completed by replacing the human-termed variables with the actual computer variables initialized, followed by actual coding
\1 Debugging is generally done by tracing the program, keeping track of the sequence of instructions and what it produced, to identify incorrect results
\2 This is often done by breaking the program into modules, checking the results of each module, easily working with structural programming
\2 For assembly language, this is done by setting specific values to see the resultant output, execute sequences using breakpoints or single instructions (single-stepping), and displaying values
\3 Breakpoints allow the result of each module or iteration, rather than each instruction, to be analyzed for errors
\2 One common bug is often corner cases as well, working for the more extreme inputs, or infinite loops
\end{outline*}
\section{Chapter 11 - Introduction to C}
\begin{outline*}
\1 Higher-level languages were necessary as programs became more complicated to automate aspects of the process
\2 This is done by providing symbolic names to values, without having to allocate storage or move data to access it
\2 In addition, it allows expressive representation of calculations and tests, rather than specific line formatting, and improves readability of the code
\2 It also has checks for bugs and error messages to aid the programmer, and has more extensive libraries
\1 High-level languages can either be interpreted (executed by an interpreter program which reads it), or compiled (translated into an executable machine language)
\2 Interpreters are also called virtual machines, executing the program as input data in a sequential manner, such as Perl, LISP, BASIC, LC-3, or LC-4
\3 This allows regions to be executed at a time, allowing easier debugging and code modifications, but longer execution
\2 Compilation requires only one time for unlimited running, but requires analyzing the complete program as a full unit, used in C and FORTRAN
\3 This allows execution quicker and more efficient resource usage, but renders debugging during the process more difficult
\1 C is made to allow writing compilers and operating systems, such that it is a high-level, but near-low-level language, allowing bitwise and memory manipulation
\2 As a result, C has been a fundamental basis of many modern languages, such as Java or C++
\2 C was made machine independent by the ANSI C version, used by most compilers, specified by the American National Standards Institute
\1 C compilers are made up of a preprocessor, finding preprocessor directives (pseudo-ops), adding header files or constants
\2 Preprocessor commands are begun by \#, generally using ``define'' to create a compiler constant, and ``include'' to add the code from a header file in
\3 Adding header files in can be used to declare variables and functions, as well as define constants, which are standardized to multiple source files, often used to declare library functions
\3 $<>$ are used to surround library header files within the system library storage, while ``'' are used for files within the same directory
\2 The compiler then produces object modules, using a symbol table, parsing code in two stages (analysis/parsing into sections, synthesis/generating and optimizing code)
\2 The linker then links all computer and user object modules together to create an executable image, finding library files in a specific OS location
\1 Functions/subroutines are defined in code by a function definition, with the main() function, which must return an int, as the start of program execution
\2 Functions are made up of variable declarations, and statements of the function (which express actions performed within the function)
\2 Declarations and statements are ended with a semicolon, to allow the compiler to easily break it into blocks, though preprocessor commands do not
\1 Input and output in C are done by library functions, commonly within ``stdio.h'', using formatted strings
\2 Formatted strings have text to print and specifications on how to print values within the text, represented by format specifications starting with \%
\2 Output is written as ``printf(\textit{string, value1, \dots})'', input done similarly by scanf(), either providing the specific value or the variable
\3 It is noted that scanf must have the values as pointer variables, providing where to store the input
\end{outline*}
\section{Appendix D - The C Programming Language}
\begin{outline*}
\1 Conventions within the C programming language is divided into source files (.c) and header files (.h)
\2 The source files are compiled into an object, linked into an executable
\2 The header files contain function, variable, structure, and type declarations, and preprocessor macros, using one for each source file, included at the top
\2 Comments begin with ``/*'', ending with ``*/'', able to span multiple lines, unable to be nested or within characters/strings
\2 Literal constant values are able to be used in expressions or used to initialize variables, defined bitwise as in assembly, explicitly written
\3 Integer literals beginning with 0 are octal, 0x are hexadecimal, otherwise a decimal, with the minus sign before the marker
\4 l or L are used as a marker for a long int, while u or U are used for an unsigned int
\3 Floating points are written with a decimal point and either a fractional, integer portion, or both, presided by a minus for negative values
\4 Floating point can also be written in scientific notation, using either an e or E at the start of the integer exponent
\4 It is defaulted as a double, though f or F can be used as a float marker, and l or L is used for a long double
\3 Character literals are surrounded by single-quotes, written in normal text, converted by the computer into ASCII
\4 \\0 or \\x are able to be used to include a non-keyboard character by the ASCII code
\4 Special characters often also have a character escape code to include it in a string, beginning by ``\\\\''
\3 String literals are surrounded by double quotes, signified by the type char*, allocated in a special portion of memory for literal constants, automatically given the `\\0' null character at the end
\4 It is noted that string literals cannot be used to fill an array after it has already been initialized
\3 Enumerator constants are symbolic integer values, defined in an enumerator list of a declaration
\3 Literals are generally avoided, using constants instead to give symbolic representation to the value
\2 C is freely formatted, such that spaces, tabs, new lines, and other formatting characters are able to be included when needed for readability
\3 It is convention to comment at the start of code when it was last modified, by whom, inputs, outputs, and the purpose of the function
\2 Keywords, used within the C language itself, are not able to be used as any form of variable, function, or object name
\1 C basic data types are int (32 bits), float, double, and char (8 bits), with char and int as integral types, the others as floating types
\2 While it is different on some machines, all tend to follow the IEEE standard
\2 The short int must be at least the size of a char in C, and the double must have a higher precision that that of a float
\2 ``signed'' and ``unsigned'' specifiers can be added to integral types, the former by default
\2 ``long'' and ``short'' specifiers can be added to either extend or shorten the length of the integral types and can shorten or lengthen the precision and/or range of floating types
\2 ``const'' specifiers can be added for variables which are not changed to optimize compilation
\1 Enumerated types allow objects to be specified of constant value from 0 onward, defined by the specified, ``enum \textit{name \{obj0 = first\_constant, \dots, objn\}}'', declared by ``enim \textit{name obj}''
\2 The objects are called enumeration constants, set such that the first is 0 by default, progressing up integrally from the first
\end{outline*}
\section{Chapter 12 - Variables and Operators}
\begin{outline*}
\1 Variables hold values within a program, while operators are used to manipulate the values
\2 Variables store data items, using symbolic representation, requiring declaration, written as ``\textit{type name;}'', reserving that amount of memory for the variable before it is used
\2 Declarations are also able to contain an initializer on the same line, such that it is written ``\textit{type name = value;}''
\2 Each basic variable type (char, float, double, int) generally take up one memory location within C, though may contain differing numbers of bits (32 for int/float generally, 16 for char, 64 for double)
\2 Variable names are called identifiers, with specific rules, such as only the first 31 characters being used, case-sensitive, and only alphanumeric and the underscore characters used
\3 Convention has all uppercase used for symbolic preprocessor values, a starting underscore for library, users using either camel-case or underscores between lowercase words
\3 Variables are also often given names that allow the code to be more clear to readers
\2 Variables are given a scope of local (in a specific block of code) or global (in the whole program) based on where they are declared
\3 Global variables are declared outside of any function or loop, while local variables are restricted to the function/control block in which they are defined
\3 Blocks are defined as any portion of code enclosed within curly brackets, able to be defined without a defining use to change variable scope
\3 Local variables are allowed to have the same name as local variables from other blocks, less vulnerable to be changed in other parts of the code, and more reusable
\3 Variables have the scope and value of the most recently defined version, such that they can be nested, redeclaring locally within a block, reverting back to the original outside
\2 Local variables are not cleared when declared, such that unless they are initialized, they could have a random value
\3 Global or other static storage class variables are automatically initialized to 0 when declared
\1 Operators are combined with variables and literals to form an expression, grouped together to form a complete statement, terminated by a semicolon
\2 Statements are able to be grouped together by curly brackets into a block/compound statement
\2 The statement ``;'' is called the null statement
\2 The assignment operator, =, evaluates the right hand side, assigning it to the variable on the left
\3 Variables are then converted into the type the variable was declared as
\2 Arithmetic operators return the highest length type given to the operator, with floating points considered longer than integral types, integers longer than characters
\3 The main operators are * (multiply), / (divide), \% (modulus), +(addition), and - (subtraction), with parentheses used to clarify the order of operations
\2 Bitwise operators include $|$ (or), \& (and), \^ (xor), ~ (not), $<<$ (left shift), and $>>$ (arithmetic right shift)
\2 Relational operators include $>$ (greater than), $>= (\geq), <= (\leq)$, $<$ (less than), == (equal), and != (not equal)
\2 Logical operators evaluate values where nonzero is considered logically true, zero logically false, including \&\& (and), || (or), ! (not)
\2 Increment operators add or subtract 1 to a variable, returning the value of the variable (++, --)
\3 If the operator is placed before the variable, it is in prefix form, returning the value of the variable after incrementing, placed after for postfix, such that it returns the value before
\3 This is used to change a variable value without the assignment operator
\2 Joint assignment operators are combined arithmetic/bitwise and assignment operators, placing the assignment operator directly after without a space, such that the resultant value is assigned to the left variable
\2 Conditional operators allow simple decisions to be made, such that it is written ``x = a ? b : c'', meaning if a, then x = b, else x = c
\2 The order of operations begins with left-associative (), [], ->, and . operators, followed by postfix increment, then prefix increment (right-associative)
\3 The indirection * operator, \& address, unary (+/-), logical and bitwise not, ``(type)'' typecast, and ``sizeof'' operators then are next with right associativity
\3 It is then followed by *, /, \%, then +, -, then shifts, then comparisons, then equality, then bitwise AND, then bitwise XOR, then bitwise OR, all left associativity
\3 After is the logical AND, then logical OR, then ?: conditional expressions, all left associative
\3 Last in the order is joint assignment operators with right associativity
\3 Associativity is the order for multiple operators with equal precedence
\1 The compiler uses a symbol table, similar to LC-4, creating an entry each time a variable is declared, allocating the storage
\2 Each symbol table entry states the name, type, memory location, and the scope of the variable
\3 The memory location is written in offset form, generally using negative offset
\2 Variables are allocated within either the global data section or the run-time stack within memory, the former for ``static'' or global variables, the latter for all other variables
\3 The offset thus describes the offset from the start of the storage region, thus in terms of a pointer to the region, such that the global pointer (R4) is a built in pointer to the start of the global data section
\3 Local variables are allocated in an activation record/stack frame/memory template, with the pointer to the final item called the frame pointer
\4 Each function call creates an activation record for that particular invocation, with a new frame pointer (R5) for the function
\4 When called, the activation record is put on the top of the run-time stack, moving the stack pointer (R6) to the new top of the stake, removing the record when the function completes
\4 As a result, variables declared locally first have an offset closer to 0, moving further negative after
\3 The program itself is also given a portion of memory, as is the dynamically allocated data heap and the OS
\1 Variables also have a storage class property, determining if it loses its value when the block in which it is declared completes, using the ``static'' declaration, acting as global variables
\2 Local variables are by default in the automatic storage class, while global are by default in static
\2 Local variables declared static are private to its block, such that it cannot be accessed/modified outside a block in which it is declared, but are able to be redeclared to be accessed further, not removed after the block
\end{outline*}
\section{Chapter 13 - Control Structures}
\begin{outline*}
\1 Control structures allow the dividing of an algorithm into the three programming constructs
\2 It is noted that all variables must be initialized outside the loop if it is to remain outside the loop
\1 Conditional constructs are divided into if and if else statements, written as ``if (\textit{conditional}) \textit{action}; else \textit{action};
\2 These are able to be nested to form else-if statements, automatically connected an else to the closed unattached if
\2 Action blocks can be surrounded by curly brackets to allow multiple statements within
\2 It is noted that == is the equality operator, while = is the assignment operator, commonly causing errors
\2 0 is a false conditional, while any nonzero value is considered to imply truth
\1 Iterative constructs are divided into while, do-while, and for statements, the first written as ``while (\textit{conditional} \textit{action}''
\2 While loops are generally used for a sentinel condition, and can be used for a counter condition
\2 For loops are used generally for counter controlled loops, written as ``for (\textit{variable-initialization; conditional; reinitialization}) \textit{action}''
\3 This defines the initial counter state, then the method of modification after each iteration of the loop
\2 Do-while loops are similar to while loops, except with the condition checked after each iteration, rather than before, written as ``do \textit{action} while \textit{(text)};''
\1 Other C constructs are the switch, break, and continue constructs, the first written as ``switch (variable) \{ case \textit{value}: \textit{action} break; \dots default: \textit{action}\}
\2 Each case must be checking for a constant value of the variable, executing it otherwise, then leaving the block by the break command
\2 The break command is not required and can also be used to leave any other iterative control structure
\3 The continue statement is used to immediately move to the next loop iteration
\2 The default is used if none of the cases are found, also not required for the construct
\end{outline*}
\section{Chapter 16 - Pointers and Arrays}
\begin{outline*}
\1 Pointers in C are defined as the address of a memory object, indirectly accessing them, while arrays are sequential lists of the same type of data, also indirectly accessed
\1 Pointers allow arguments to be passed by memory instead of by value into a function, such that the memory itself can be changed, rather than simply modifying the variables in the function stack temporarily
\2 The process of using pointers instead of calling a function by value is called calling by reference, giving the memory addresses
\3 Pointers also allow a function to return multiple values, since the return function can only provide a single variable
\3 This then returns -1 to show an error, 0 to show no error, adjusting the input memory locations instead
\2 Pointer variables are associated with the type of object they point to, such that it is declared by ``\textit{type} *\textit{varname}'', storing the memory address
\3 It is declared like this due to stating that the variable is of that type when dereferenced
\2 The address operator, \&, returns the memory address of the variable, allowing it to be stored in the pointer, written ``\textit{pointer-var} = \&\textit{variable};''
\2 The indirection/dereference operator, *, can be used before a pointer variable to allow accessing the data stored at the location in the pointer
\2 Null pointers are able to be made by initializing to ``NULL'', a built-in macro for an invalid pointer value
\1 Arrays are declared based on the type contained within by ``\textit{type name\[size\]}'', unable to have their size changed after declaration
\2 Arrays must be given an explicit size within code, rather than a variable size, or a syntax error will occur
\2 Items are able to be accessed by index, such that the ith element in the array is taken by ``\textit{name\[i-1\]}''
\3 Indices are useful in being able to be represented by any integer representation, including symbolic
\2 Arrays can be passed as parameters, automatically done by reference, due to the array variable name acting as a pointer to the first item in the array
\3 As a result, ``\textit{name\[1\]}'' is equivelent to ``*(\textit{name} + 1)''
\4 It is noted that while pointers can be reassigned as variables, array variables are fixed to the location for the duration of the stack
\2 Arrays are also used for strings, acting as a character array, with a sentinel null character `\\0', called null-terminated strings
\3 String literals are written within double quots, rather than single quotes, written in printf() by the \%s specifier
\3 The compiler automatically adds the null character to the end of the string
\3 The length of the string array states the maximum possible length of the string, but does not specify the actual string character length
\4 If the scanf() call exceeds the length of the array, it will overwrite variables stored after the string, writing remaining characters after the array
\4 This is due to the lack of protection built-in to C against exceeding array size to save time
\3 It is noted that in C, scanf() only reads until the first white space for a string, keeping the remainder in a buffer for future scanf() calls
\3 String specific functions are found within the C standard library, declared in string.h
\end{outline*}
\section{Chapter 10 - The Stack}
\begin{outline*}

\end{outline*}
\section{Chapter 14 - Functions}
\begin{outline*}

\end{outline*}
\end{document}
