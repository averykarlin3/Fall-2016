\documentclass[11 pt, twoside]{article}
\usepackage{textcomp}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{indentfirst} %Comment out for no first paragraph indent
\usepackage[parfill]{parskip}
\usepackage{setspace}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{outlines}

\usepackage{fancyhdr}
\pagestyle{fancy}
\cfoot{\hyperlink{content}{\thepage}}
\lhead{}
\chead{}
\rfoot{}
\lfoot{}
\rhead{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}


\usepackage{hyperref}
\hypersetup {
	colorlinks,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black
}

\newcommand{\sepitem}{0pt} %Added room between items on the list, not including a list and its sublist
\newcommand{\seppar}{1pt} %Between items and lists overall

\setenumerate[1]{itemsep=\sepitem, parsep=\seppar}
\setenumerate[2]{itemsep=\sepitem, parsep=\seppar}
\setenumerate[3]{itemsep=\sepitem, parsep=\seppar}
\setenumerate[4]{itemsep=\sepitem, parsep=\seppar}

\newenvironment{outline*}
{
	\begin{outline}[enumerate]
	}
	{\end{outline}
}

\newcommand{\foot}[1]{\hyperlink{#1}{$_#1$}}

\begin{document}

\title{}
\author{Avery Karlin}
\date{}
\newcommand{\textbook}{}
\newcommand{\teacher}{}

\maketitle
\newpage
\hypertarget{content}{\tableofcontents}
\vspace{11pt}
\noindent
\underline{Primary Textbook}: \textbook\\
\underline{Teacher}: \teacher
\newpage

\section{Chapter 1 - Introduction}
\begin{outline*}
\1 Computer systems are viewed from a bottom up approach of how transistors run basic programs and a top down approach of how complicated programs are converted into simple logic commands
\2 This is used to understand commands a computer does well and does badly to program more efficiently, and to understand how changes in technology change the speed of computing
\2 C is used due to being high level enough to write large programs, but low level enough to allow direct modification of bits
\1 The concept of abstraction is central to computer science, focusing on a higher level, rather than the component ideas to save time and mental effort, assuming the details work
\2 On the other hand, it must go in turn with deconstruction, breaking down an abstract idea into more concert sub-ideas, the opposite of abstraction, in case there is a problem
\1 The concept of viewing hardware and software as joint components of a single system, which must both be taken into account to design either, is another central idea, to design the most effective components
\1 Processors/CPUs are the primary unit of a computer, used to direct the processing of information and perform the calculations required to process it, though there are other components to make use easier
\2 Originally, they were made of large boards covered in integrated circuit packages, but now are just a single silicon microprocessor chip with millions of transistors
\1 The only limitations of computers are time and amount of memory, but otherwise all computers can do the same tasks, though not at the same pace
\2 This is due to computers being universal computing devices, as digital machines which could be increased in precision unlike analog/physical machines, but which were not made for individual tasks
\2 Turing in 1937 proposed the Turing machine, which would be able to carry out all computations of some type, and later began to define what computation is, abstracting tasks by a black box model, showing the task, input, and output, with no specification about how it is performed
\3 Turing's thesis states that a Turing machine can do all computations, such that improvements to it do not change the amount of computations, making a universal Turing machine able to simulate all different Turing machines
\2 Computers/universal Turing machines are able to do any computations, due to being programmable
\1 Computer problems must be converted into voltages to influence the flow of electrons which the computer is made of, made of a series of methods to allow carrying out of complex tasks
\2 The levels of transformation are the levels of choice to convert the problem into an electron flow for the computer, starting with the statement in a natural/human language, which has too much ambiguity to give directly to the computer
\2 The first transformation is to an algorithm, or a finite step by step procedure, with definiteness, or precisely stated, and effective compatibility, or able to be carried out by a computer,
\3 There are many possible algorithms, depending on the number of steps allowed concurrently by the computer, with many different speeds and lengths
\2 After, it is converted to a mechanical/programming language, specifically created to avoid ambiguity, often designed for specific purposes
\3 High level languages are those far from the computer itself, often machine independent, such that they don't rely on the computer specifics, such as C
\3 Low level languages are specific to the computer, such that there is one for each computer generally, called assembly
\2 The third level is conversion into the computers instruction set architecture (ISA), or the specification of interface between programs and the hardware, generally x86 on Intel processors
\3 The ISA specifies the instructions and operations the computer can do, what inputs (operands) it requires, and the operand formats (data types) it is able to accept
\3 It also contains mechanisms for the computer to find operands, called addressing modes, the number of unique memory locations, and the number of bits in each location
\3 High level languages are converted to ISA format by a compiler, while low level languages are converted by an assembler
\2 After, the ISA is transformed into an implementation, based on the microprocessor-specific microarchitecture
\3 Unlike the ISA, which specifies what the computer can do, the microarchitecture specifies how the computer actually performs those tasks
\2 The microarchitecture is made out of logic circuits, determining the trade-off of cost and efficiency during manufacturing, each of which is further made out of a specific type of circuit materials, with its own specifications
\end{outline*}
\section{Chapter 2 - Bits, Data Types, and Operations}
\begin{outline*}
\1 The movement of electrons is controlled by devices reacting to the presence of voltage, rather than the amount for simplicity
\2 These voltages are signified by binary digits/bits, 1 for voltage near the maximum, and 0 for voltage near zero (rounding due to device variation)
\2 Bits are then combined to get a large number of distinct values
\1 Data types are representations of values in which operations are encoded within the data types, mainly using 2's complement integers, ASCII codes, and floating points
\2 Unsigned integers are used to identify locations and counts, represented by positional binary representation, ranging from 0 to $2^k - 1$ for k binary digits
\2 Signed integers are used for arithmetic, with a leading 0 to signify positive, from 0 to $2^{k-1} - 1$ for k binary digits, using different systems for negative
\3 The signed magnitude system uses a leading 1 for a negative value, with a leading 1 on 0 signifying -0
\3 The 1's complement system uses a leading 1 for negative values, signifying it is equivalent to switching every other binary digit in the value (complement) to get the magnitude
\3 The 2's complement system is the standard data type, equivalent to the 1's complement - 1 for each negative value, found to be easiest to design hardware to do arithmetic on
\1 Computers generally use an arithmetic and logic unit (ALU) for addition, converting two inputs to one output of the sum, performing it in the same column method with carrying as standard addition, without actually determining the values, leading to the 2's complement system
\2 Thus, it is necessary for the sum of a number and its inverse to equal 0, ignoring all extra digits, such that only the correct number of digits is kept, and it is necessary for the sequence to be equal to one added, such that it works for results in the range, providing the advantage of the complements
\2 The advantage of 2's complement over 1's complement is making full use of the maximum amount of digits, rather than having two versions of 0
\2 The precision of the value is the number of numerical bits, while the range is the maximum magnitude of the bit sequence
\1 Since addition is the main arithmetic bit operation, subtraction of bits is simply done by adding the additive inverse of the second value
\2 Doubling the value of positive 2's complement bits is equivalent to shifting bits to the right by one, though this is not true for negative bits
\2 Sign extension/SEXT is used to shrink the amounts of bits used for a smaller number, removing all but one leading zero for positive, all but one leading one for negative
\3 Vice versa, the leading digits can be added, due to requiring the same number of bits used for adding or subtracting
\2 Overflow is noted by the loss of the leading digit, such that the sum of two positive is negative, or vice versa, such it can be dealt with
\1 Logical operations are based on viewing binary as true/1 and false/0, and are binary functions, requiring two logical inputs/bits
\2 They are also able to be used on sequences of bits of the same length, testing corresponding bits from each
\3 Bit masks are sequences which are used to separate/modify specific bits from a sequence, using logical operations
\2 Bit-wise AND returns 1 iff both inputs are 1, bit-wise OR (inclusive OR) returns 0 iff both inputs are 0, and bit-wise XOR (exclusive OR) returns 1 iff only one of the inputs is 1
\2 The NOT/complement function takes a single input (unary function), inverting/switching each of the bits in the sequence
\1 Bit vectors are binary sequences used to track if units are available/1 or busy/0, numbering units from right to left, starting with 0
\1 Floating points are used to describe numbers of a high range, but low precision, in terms of scientific notation, such that for a 32 bit float, 1 signifies the sign, then 8 for the range/exponent, then 23 for the precision/fraction
\2 Thus, the number is equal to (1 + fraction) * $2^{exponent - 2^7 + 1}$, where the exponent is not allowed to be 0 or the maximum exponent
\3 If the exponent is 0, it is modified to 1 under the IEEE Standard for Floating Point Arithmetic
\2 The fraction is found by converting the numerator and whole number to binary, then shifting to find the real exponent value, such that the fraction is the sequence except the leading 1
\3 This is done similarly to how it would be found for scientific notation, except that both parts are converted to binary before
\1 ASCII (American Standard Code for Information Interchange) converts character codes from input and output into unique 8 bit codes universally
\2 As a result, keys generally have multiple associated codes, due to different characters able to be produced by each
\1 Hexadecimal notation easily is produced from binary, taking 4 bit blocks into binary digits for human ease
\end{outline*}
\end{document}
